{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9315fbe",
   "metadata": {},
   "source": [
    "# Getting the relation between baroclinic streamfunction and cross-stream distance from the Argo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c2126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import gsw\n",
    "import csaps\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd011f02",
   "metadata": {},
   "source": [
    "## Sample points along hydrographic section transect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10e2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in hydrographic section data\n",
    "data = loadmat('data/SR1b_section/sr1b_all.mat')\n",
    "\n",
    "icyc = np.where(data['buf_year'] != 1999)[1] # exclude 1999 # TODO: why?\n",
    "\n",
    "buf_lat = data['buf_lat'][0,icyc]\n",
    "buf_lon = data['buf_lon'][0,icyc]\n",
    "buf_sal = data['buf_sal'][:,icyc]\n",
    "buf_temp = data['buf_temp'][:,icyc]\n",
    "buf_press = data['buf_press'].reshape(3000)\n",
    "buf_year = data['buf_year'][:,icyc].reshape(316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample points along section\n",
    "start_lon_vals = []\n",
    "end_lon_vals = []\n",
    "start_lat_vals = []\n",
    "end_lat_vals = []\n",
    "for yr in np.unique(buf_year):\n",
    "  idx_yr = np.where(buf_year == yr)[0]\n",
    "  start_lon_vals.append(np.min(buf_lon[idx_yr]))\n",
    "  end_lon_vals.append(np.max(buf_lon[idx_yr]))\n",
    "  start_lat_vals.append(np.max(buf_lat[idx_yr]))\n",
    "  end_lat_vals.append(np.min(buf_lat[idx_yr]))\n",
    "start_lon = np.mean(np.array(start_lon_vals))\n",
    "end_lon = np.mean(np.array(end_lon_vals))\n",
    "start_lat = np.mean(np.array(start_lat_vals))\n",
    "end_lat = np.mean(np.array(end_lat_vals))\n",
    "\n",
    "# Extract unique points along the section\n",
    "nr_points = 30\n",
    "lon_along_section = np.linspace(start_lon, end_lon, nr_points)\n",
    "lat_along_section = np.linspace(start_lat, end_lat, nr_points)\n",
    "\n",
    "# calculate distance from southern end of section\n",
    "dist_along_section = np.zeros(len(lat_along_section))\n",
    "for i in range(len(dist_along_section)):\n",
    "  dist_along_section[i] = gsw.distance(np.mean(lon_along_section)*np.ones(2), np.array([min(lat_along_section), lat_along_section[i]]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c86f2",
   "metadata": {},
   "source": [
    "## Process the Argo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69b2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "argo_salt_dataset = xr.open_dataset('data/Argo_data/RG_ArgoClim_Salinity_2019.nc',decode_times=False)\n",
    "argo_temp_dataset = xr.open_dataset('data/Argo_data/RG_ArgoClim_Temperature_2019.nc',decode_times=False)\n",
    "# downloaded from https://sio-argo.ucsd.edu/RG_Climatology.html on 14 July 2025\n",
    "\n",
    "argo_salt_mean_all = xr.DataArray(argo_salt_dataset['ARGO_SALINITY_MEAN'].values,\n",
    "                                  dims = ['PRESSURE', 'LATITUDE', 'LONGITUDE'],\n",
    "                                  coords = {'PRESSURE': argo_salt_dataset['PRESSURE'].values,\n",
    "                                        'LATITUDE': argo_salt_dataset['LATITUDE'].values,\n",
    "                                        'LONGITUDE': argo_salt_dataset['LONGITUDE'].values})\n",
    "argo_salt_anom_all = xr.DataArray(argo_salt_dataset['ARGO_SALINITY_ANOMALY'].values,\n",
    "                                  dims = ['TIME', 'PRESSURE', 'LATITUDE', 'LONGITUDE'],\n",
    "                                  coords = {'TIME': argo_salt_dataset['TIME'].values,\n",
    "                                        'PRESSURE': argo_salt_dataset['PRESSURE'].values,\n",
    "                                        'LATITUDE': argo_salt_dataset['LATITUDE'].values,\n",
    "                                        'LONGITUDE': argo_salt_dataset['LONGITUDE'].values})\n",
    "\n",
    "argo_temp_mean_all = xr.DataArray(argo_temp_dataset['ARGO_TEMPERATURE_MEAN'].values,\n",
    "                                  dims = ['PRESSURE', 'LATITUDE', 'LONGITUDE'],\n",
    "                                  coords = {'PRESSURE': argo_temp_dataset['PRESSURE'].values,\n",
    "                                        'LATITUDE': argo_temp_dataset['LATITUDE'].values,\n",
    "                                        'LONGITUDE': argo_temp_dataset['LONGITUDE'].values})\n",
    "argo_temp_anom_all = xr.DataArray(argo_temp_dataset['ARGO_TEMPERATURE_ANOMALY'].values,\n",
    "                                  dims = ['TIME', 'PRESSURE', 'LATITUDE', 'LONGITUDE'],\n",
    "                                  coords = {'TIME': argo_temp_dataset['TIME'].values,\n",
    "                                        'PRESSURE': argo_temp_dataset['PRESSURE'].values,\n",
    "                                        'LATITUDE': argo_temp_dataset['LATITUDE'].values,\n",
    "                                        'LONGITUDE': argo_temp_dataset['LONGITUDE'].values})\n",
    "\n",
    "# select region of interest\n",
    "argo_salt_mean = argo_salt_mean_all.sel(LATITUDE=slice(-62, -53), LONGITUDE=slice(300, 307))\n",
    "argo_salt_anom = argo_salt_anom_all.sel(LATITUDE=slice(-62, -53), LONGITUDE=slice(300, 307))\n",
    "argo_salinity = argo_salt_anom + argo_salt_mean\n",
    "\n",
    "argo_temp_mean = argo_temp_mean_all.sel(LATITUDE=slice(-62, -53), LONGITUDE=slice(300, 307))\n",
    "argo_temp_anom = argo_temp_anom_all.sel(LATITUDE=slice(-62, -53), LONGITUDE=slice(300, 307))\n",
    "argo_temperature = argo_temp_anom + argo_temp_mean\n",
    "\n",
    "argo_time = argo_salinity['TIME'].values\n",
    "argo_pressure = argo_salinity['PRESSURE'].values\n",
    "argo_lat = argo_salinity['LATITUDE'].values\n",
    "argo_lon = argo_salinity['LONGITUDE'].values - 360 # convert to -180 to 180 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53ddeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate absolute salinity and conservative temperature\n",
    "# argo_SA = np.zeros(np.shape(argo_salinity))\n",
    "# for t in range(len(argo_time)):\n",
    "#     for d in range(len(argo_pressure)):\n",
    "#         for i in range(len(argo_lat)):\n",
    "#             for j in range(len(argo_lon)):\n",
    "#                 argo_SA[t,d,i,j] = gsw.SA_from_SP(argo_salinity[t,d,i,j], argo_pressure[d], argo_lon[j], argo_lat[i])\n",
    "# np.save('data/Argo_data/Argo_SA.npy', argo_SA)\n",
    "argo_SA = xr.DataArray(np.load('data/Argo_data/Argo_SA.npy'), \n",
    "                        dims=['TIME', 'PRESSURE', 'LATITUDE', 'LONGITUDE'],\n",
    "                        coords={'TIME': argo_time,\n",
    "                                'PRESSURE': argo_pressure,\n",
    "                                'LATITUDE': argo_lat,\n",
    "                                'LONGITUDE': argo_lon})\n",
    "argo_CT = gsw.CT_from_pt(argo_SA, argo_temperature.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2f989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate SA and CT to section points\n",
    "SA_section_argo = np.zeros((len(argo_time), len(argo_pressure), len(lat_along_section)))\n",
    "CT_section_argo = np.zeros((len(argo_time), len(argo_pressure), len(lat_along_section)))\n",
    "points = np.array([(lat, lon) for lat,lon in zip(lat_along_section,lon_along_section)])\n",
    "for i in range(len(argo_time)):\n",
    "    for j in range(len(argo_pressure)):\n",
    "        f_SA_argo = RegularGridInterpolator((argo_lat, argo_lon), argo_SA.values[i,j,:,:])\n",
    "        f_CT_argo = RegularGridInterpolator((argo_lat, argo_lon), argo_CT.values[i,j,:,:])\n",
    "        SA_section_argo[i,j,:] = f_SA_argo(points)\n",
    "        CT_section_argo[i,j,:] = f_CT_argo(points)\n",
    "\n",
    "# interpolate in p (to high resolution)\n",
    "SA_section_interp_argo = np.zeros((len(argo_time), len(buf_press), len(lat_along_section)))\n",
    "CT_section_interp_argo = np.zeros((len(argo_time), len(buf_press), len(lat_along_section)))\n",
    "for i in range(len(argo_time)):\n",
    "    for j in range(len(lat_along_section)):\n",
    "        f_SA_argo = interp1d(argo_pressure, SA_section_argo[i,:,j], bounds_error=False, fill_value=np.nan)\n",
    "        f_CT_argo = interp1d(argo_pressure, CT_section_argo[i,:,j], bounds_error=False, fill_value=np.nan)\n",
    "        SA_section_interp_argo[i,:,j] = f_SA_argo(buf_press)\n",
    "        CT_section_interp_argo[i,:,j] = f_CT_argo(buf_press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf15eda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/5664187/miniconda3/envs/carlo/lib/python3.13/site-packages/csaps/_sspumv.py:301: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  u = la.spsolve(a, b)\n"
     ]
    }
   ],
   "source": [
    "# compute baroclinic streamfunction\n",
    "gpan_argo = np.zeros((len(argo_time), len(buf_press), len(lat_along_section)))\n",
    "for i in range(len(argo_time)):\n",
    "    gpan_argo[i,:,:] = -gsw.geo_strf_dyn_height(SA_section_interp_argo[i,:,:], CT_section_interp_argo[i,:,:], buf_press, 1500)\n",
    "\n",
    "argo_phi1500 = abs(gpan_argo[:,249,:])\n",
    "\n",
    "# make spline fit through relationship between phi1500 and distance\n",
    "# dist_repeat = np.tile(dist_along_section, len(argo_time))\n",
    "# argo_phi1500_flatten = argo_phi1500.flatten()\n",
    "# pp_dist_argo = csaps.csaps(argo_phi1500_flatten[np.argsort(argo_phi1500_flatten)],\n",
    "#                            dist_repeat[np.argsort(argo_phi1500_flatten)],\n",
    "#                            smooth = 0.85)\n",
    "\n",
    "# also do it for the subset 2010-2012\n",
    "argo_phi1500_sub = argo_phi1500[6*12:8*12,:]  # select 2010-2012\n",
    "argo_time_sub = argo_time[6*12:8*12]  # select 2010-2012\n",
    "dist_repeat_sub = np.tile(dist_along_section, len(argo_time_sub))\n",
    "argo_phi1500_flatten_sub = argo_phi1500_sub.flatten()\n",
    "pp_dist_argo = csaps.csaps(argo_phi1500_flatten_sub[np.argsort(argo_phi1500_flatten_sub)],\n",
    "                           dist_repeat_sub[np.argsort(argo_phi1500_flatten_sub)],\n",
    "                           smooth = 0.85)\n",
    "\n",
    "# save the spline fit\n",
    "with open('data/Argo_data/pp_dist_argo.pkl', 'wb') as f:\n",
    "    pickle.dump(pp_dist_argo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59dc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carlo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
